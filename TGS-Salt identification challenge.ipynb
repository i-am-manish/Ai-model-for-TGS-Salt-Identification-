{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "scrolled": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport cv2\nfrom tqdm import tqdm #Progress bar\nimport os\nTRAIN_IMAGE_DIR = '../input/train/images/' #img_id is x(input)\nTRAIN_MASK_DIR = '../input/train/masks/'   #rle_mask is y(output)\nTEST_IMAGE_DIR = '../input/test/images/'\n\ntrain_d = os.listdir(TRAIN_IMAGE_DIR) ",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "45923ae892c8b53531c0ba262290b1b1721a9ab7"
      },
      "cell_type": "code",
      "source": "x = [np.array(cv2.imread(TRAIN_IMAGE_DIR + p, cv2.IMREAD_GRAYSCALE), dtype=np.uint8) for p in tqdm(train_d)] #cv2.imread=openCV image read\nx = np.array(x)/255\n\ny = [np.array(cv2.imread(TRAIN_MASK_DIR + p, cv2.IMREAD_GRAYSCALE), dtype=np.uint8) for p in tqdm(train_d)]\ny = np.array(y)/255\nprint(x.shape,y.shape)",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 4000/4000 [00:03<00:00, 1205.04it/s]\n100%|██████████| 4000/4000 [00:02<00:00, 1704.06it/s]\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "(4000, 101, 101) (4000, 101, 101)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e2e7c9d0bd2f3a4c315b5605fff943d1229084b"
      },
      "cell_type": "code",
      "source": "x=np.expand_dims(x,axis=3) #EXPAND DIM OF X AND INSERT NEW AXIS @ 3 \ny=np.expand_dims(y,axis=3)\nprint(x.shape,y.shape)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(4000, 101, 101, 1) (4000, 101, 101, 1)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "22b0c6b5e35da90720ef2224500df4dd493a7f26"
      },
      "cell_type": "code",
      "source": "from keras.layers import MaxPooling2D,Conv2D,Dense,Dropout,Input,Conv2DTranspose,Concatenate\nfrom keras.models import Sequential,Model\nfrom keras.optimizers import Adam\nimport keras\ndef conv_block(num_layers,inp,units,kernel_size):\n    x = input\n    for l in range(num_layers): #repeat 32-24-16 ----4 times\n        x = Conv2D(units, kernel_size=kernel_size,padding='SAME',activation='relu')(x)\n    return x\ninput = Input(shape=(101,101,1))\ncnn1 = conv_block(5,input,32,3)\ncnn2 = conv_block(5,input,24,5)\ncnn3 = conv_block(5,input,16,7)\ncnn4 = conv_block(5,input,8,9)\ncnn5 = conv_block(5,input,4,11)\nconcat = Concatenate()([cnn1,cnn2,cnn3,cnn4,cnn5])\n\nd1 = Conv2D(16,1,activation='relu')(concat)\nout = Conv2D(1,1,activation='sigmoid')(d1) #filter_size = 1 ,so that 1x1 filter will scan over for more learning\n\nmodel = Model(inputs=[input], outputs=[out])\nadam=Adam(lr=0.001)\nmodel.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\nmodel.summary() # start_dim=(101,101,1) == #end_dim=(101,101,1)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, 101, 101, 1)  0                                            \n__________________________________________________________________________________________________\nconv2d_1 (Conv2D)               (None, 101, 101, 32) 320         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_6 (Conv2D)               (None, 101, 101, 24) 624         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_11 (Conv2D)              (None, 101, 101, 16) 800         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 101, 101, 8)  656         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (None, 101, 101, 4)  488         input_1[0][0]                    \n__________________________________________________________________________________________________\nconv2d_2 (Conv2D)               (None, 101, 101, 32) 9248        conv2d_1[0][0]                   \n__________________________________________________________________________________________________\nconv2d_7 (Conv2D)               (None, 101, 101, 24) 14424       conv2d_6[0][0]                   \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 101, 101, 16) 12560       conv2d_11[0][0]                  \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 101, 101, 8)  5192        conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (None, 101, 101, 4)  1940        conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nconv2d_3 (Conv2D)               (None, 101, 101, 32) 9248        conv2d_2[0][0]                   \n__________________________________________________________________________________________________\nconv2d_8 (Conv2D)               (None, 101, 101, 24) 14424       conv2d_7[0][0]                   \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 101, 101, 16) 12560       conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 101, 101, 8)  5192        conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (None, 101, 101, 4)  1940        conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nconv2d_4 (Conv2D)               (None, 101, 101, 32) 9248        conv2d_3[0][0]                   \n__________________________________________________________________________________________________\nconv2d_9 (Conv2D)               (None, 101, 101, 24) 14424       conv2d_8[0][0]                   \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 101, 101, 16) 12560       conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 101, 101, 8)  5192        conv2d_18[0][0]                  \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (None, 101, 101, 4)  1940        conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nconv2d_5 (Conv2D)               (None, 101, 101, 32) 9248        conv2d_4[0][0]                   \n__________________________________________________________________________________________________\nconv2d_10 (Conv2D)              (None, 101, 101, 24) 14424       conv2d_9[0][0]                   \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 101, 101, 16) 12560       conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (None, 101, 101, 8)  5192        conv2d_19[0][0]                  \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (None, 101, 101, 4)  1940        conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 101, 101, 84) 0           conv2d_5[0][0]                   \n                                                                 conv2d_10[0][0]                  \n                                                                 conv2d_15[0][0]                  \n                                                                 conv2d_20[0][0]                  \n                                                                 conv2d_25[0][0]                  \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (None, 101, 101, 16) 1360        concatenate_1[0][0]              \n__________________________________________________________________________________________________\nconv2d_27 (Conv2D)              (None, 101, 101, 1)  17          conv2d_26[0][0]                  \n==================================================================================================\nTotal params: 177,721\nTrainable params: 177,721\nNon-trainable params: 0\n__________________________________________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "19cc3338c1d337414d9a864355f3001475bb229a"
      },
      "cell_type": "code",
      "source": "keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')\nmodel.fit(x,y,epochs=50,batch_size=128,validation_split=0.2,verbose=True)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 3200 samples, validate on 800 samples\nEpoch 1/50\n3200/3200 [==============================] - 37s 12ms/step - loss: 0.5963 - acc: 0.7284 - val_loss: 0.5478 - val_acc: 0.7532\nEpoch 2/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.5123 - acc: 0.7517 - val_loss: 0.4995 - val_acc: 0.7532\nEpoch 3/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.4717 - acc: 0.7549 - val_loss: 0.4996 - val_acc: 0.8098\nEpoch 4/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.4611 - acc: 0.7839 - val_loss: 0.4277 - val_acc: 0.8114\nEpoch 5/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.4260 - acc: 0.8141 - val_loss: 0.3911 - val_acc: 0.8322\nEpoch 6/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.4219 - acc: 0.8164 - val_loss: 0.3913 - val_acc: 0.8391\nEpoch 7/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.4055 - acc: 0.8274 - val_loss: 0.3818 - val_acc: 0.8396\nEpoch 8/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.4011 - acc: 0.8288 - val_loss: 0.3579 - val_acc: 0.8525\nEpoch 9/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.4001 - acc: 0.8289 - val_loss: 0.4145 - val_acc: 0.8206\nEpoch 10/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3800 - acc: 0.8420 - val_loss: 0.3484 - val_acc: 0.8592\nEpoch 11/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3618 - acc: 0.8514 - val_loss: 0.3419 - val_acc: 0.8626\nEpoch 12/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3568 - acc: 0.8562 - val_loss: 0.3450 - val_acc: 0.8649\nEpoch 13/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3603 - acc: 0.8541 - val_loss: 0.3524 - val_acc: 0.8541\nEpoch 14/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3578 - acc: 0.8555 - val_loss: 0.3620 - val_acc: 0.8528\nEpoch 15/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3666 - acc: 0.8510 - val_loss: 0.3293 - val_acc: 0.8716\nEpoch 16/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3519 - acc: 0.8587 - val_loss: 0.3392 - val_acc: 0.8713\nEpoch 17/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3469 - acc: 0.8620 - val_loss: 0.3282 - val_acc: 0.8709\nEpoch 18/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3389 - acc: 0.8665 - val_loss: 0.3176 - val_acc: 0.8784\nEpoch 19/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3351 - acc: 0.8690 - val_loss: 0.3119 - val_acc: 0.8819\nEpoch 20/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3347 - acc: 0.8683 - val_loss: 0.3092 - val_acc: 0.8821\nEpoch 21/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3321 - acc: 0.8698 - val_loss: 0.3007 - val_acc: 0.8866\nEpoch 22/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3362 - acc: 0.8673 - val_loss: 0.3029 - val_acc: 0.8850\nEpoch 23/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3279 - acc: 0.8698 - val_loss: 0.3066 - val_acc: 0.8842\nEpoch 24/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3223 - acc: 0.8729 - val_loss: 0.2979 - val_acc: 0.8853\nEpoch 25/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3201 - acc: 0.8740 - val_loss: 0.3034 - val_acc: 0.8853\nEpoch 26/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3193 - acc: 0.8751 - val_loss: 0.3036 - val_acc: 0.8846\nEpoch 27/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3244 - acc: 0.8718 - val_loss: 0.3074 - val_acc: 0.8847\nEpoch 28/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3212 - acc: 0.8748 - val_loss: 0.2906 - val_acc: 0.8915\nEpoch 29/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3292 - acc: 0.8710 - val_loss: 0.3126 - val_acc: 0.8798\nEpoch 30/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3188 - acc: 0.8752 - val_loss: 0.3006 - val_acc: 0.8912\nEpoch 31/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3136 - acc: 0.8773 - val_loss: 0.3225 - val_acc: 0.8776\nEpoch 32/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3229 - acc: 0.8705 - val_loss: 0.2987 - val_acc: 0.8888\nEpoch 33/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3160 - acc: 0.8763 - val_loss: 0.2825 - val_acc: 0.8935\nEpoch 34/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3091 - acc: 0.8794 - val_loss: 0.2844 - val_acc: 0.8935\nEpoch 35/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3123 - acc: 0.8776 - val_loss: 0.3014 - val_acc: 0.8885\nEpoch 36/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3077 - acc: 0.8801 - val_loss: 0.2907 - val_acc: 0.8929\nEpoch 37/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3063 - acc: 0.8799 - val_loss: 0.2908 - val_acc: 0.8863\nEpoch 38/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3084 - acc: 0.8783 - val_loss: 0.2825 - val_acc: 0.8931\nEpoch 39/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.3045 - acc: 0.8811 - val_loss: 0.2780 - val_acc: 0.8941\nEpoch 40/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2959 - acc: 0.8832 - val_loss: 0.2765 - val_acc: 0.8959\nEpoch 41/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2998 - acc: 0.8828 - val_loss: 0.2757 - val_acc: 0.8955\nEpoch 42/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2965 - acc: 0.8837 - val_loss: 0.2768 - val_acc: 0.8953\nEpoch 43/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2903 - acc: 0.8852 - val_loss: 0.2758 - val_acc: 0.8971\nEpoch 44/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2893 - acc: 0.8860 - val_loss: 0.2658 - val_acc: 0.9015\nEpoch 45/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2850 - acc: 0.8866 - val_loss: 0.2704 - val_acc: 0.8969\nEpoch 46/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2908 - acc: 0.8853 - val_loss: 0.2722 - val_acc: 0.8966\nEpoch 47/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2874 - acc: 0.8867 - val_loss: 0.2677 - val_acc: 0.8981\nEpoch 48/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2907 - acc: 0.8853 - val_loss: 0.2827 - val_acc: 0.8923\nEpoch 49/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2883 - acc: 0.8865 - val_loss: 0.2714 - val_acc: 0.8973\nEpoch 50/50\n3200/3200 [==============================] - 28s 9ms/step - loss: 0.2869 - acc: 0.8869 - val_loss: 0.2620 - val_acc: 0.9007\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7f503ae05be0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1cfdb4872b4706d61a8c201d90519dae995a05f"
      },
      "cell_type": "code",
      "source": "#test_data\ntest_d=os.listdir(TEST_IMAGE_DIR)\n\nx_test = [np.array(cv2.imread(TEST_IMAGE_DIR + p, cv2.IMREAD_GRAYSCALE), dtype=np.uint8) for p in tqdm(test_d)]\nx_test = np.array(x_test)/255\nprint(x_test.shape)\nx_test = np.expand_dims(x_test,axis=3)\nprint(x_test.shape)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 18000/18000 [00:18<00:00, 993.98it/s]\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "(18000, 101, 101)\n(18000, 101, 101, 1)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7cbc9c8cf80e6742989de0207adf5c5e3818cd31"
      },
      "cell_type": "code",
      "source": "predict=model.predict(x_test,verbose=True)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "18000/18000 [==============================] - 61s 3ms/step\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "52f38eeb3caaf76a164e640128a9e5a1071f06a7"
      },
      "cell_type": "code",
      "source": "#copy-pasted for rendering\ndef RLenc(img, order='F', format=True):\n    \"\"\"\n    img is binary mask image, shape (r,c)\n    order is down-then-right, i.e. Fortran\n    format determines if the order needs to be preformatted (according to submission rules) or not\n\n    returns run length as an array or string (if format is True)\n    \"\"\"\n    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n    runs = []  ## list of run lengths\n    r = 0  ## the current run length\n    pos = 1  ## count starts from 1 per WK\n    for c in bytes:\n        if (c == 0):\n            if r != 0:\n                runs.append((pos, r))\n                pos += r\n                r = 0\n            pos += 1\n        else:\n            r += 1\n            \n    # if last run is unsaved (i.e. data ends with 1)\n    if r != 0:\n        runs.append((pos, r))\n        pos += r\n        r = 0\n\n    if format:\n        z = ''\n\n        for rr in runs:\n            z += '{} {} '.format(rr[0], rr[1])\n        return z[:-1]\n    else:\n        return runs\n\npred_dict = {fn[:-4]:RLenc(np.round(predict[i,:,:,0])) for i,fn in tqdm(enumerate(test_d))}",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "18000it [05:35, 53.67it/s]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a815403a60cd43ae858f6475090c0e47d8a38e99",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import pandas as pd\nsub = pd.DataFrame.from_dict(pred_dict,orient='index')\nsub.index.names = ['id']\nsub.columns = ['rle_mask']\nsub.to_csv('submission.csv')\n",
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "36b024e23cc8ca96f35b23b03aceff1540d5d6ee"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}